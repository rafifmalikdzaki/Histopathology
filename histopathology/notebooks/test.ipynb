{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:05:38.447646Z",
     "start_time": "2024-11-29T07:05:36.295991Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def read_tif_image(image_path):\n",
    "    \"\"\"\n",
    "    Read a TIF image\n",
    "    \"\"\"\n",
    "    img = tifffile.imread(image_path)\n",
    "    if img.dtype == np.uint16:\n",
    "        img = ((img / img.max()) * 255).astype(np.uint8)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    elif len(img.shape) == 3 and img.shape[2] > 3:\n",
    "        img = img[:, :, :3]\n",
    "\n",
    "    return img\n",
    "\n",
    "def extract_colored_boxes(img):\n",
    "    \"\"\"\n",
    "    Extract the existing red, green, and yellow boxes\n",
    "    Focus on single-pixel width lines\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Create individual channel masks\n",
    "    b, g, r = cv2.split(img)\n",
    "\n",
    "    # Define masks for each color (pure RGB values)\n",
    "    red_mask = cv2.bitwise_and(cv2.compare(r, 253, cv2.CMP_GE),\n",
    "                               cv2.bitwise_and(cv2.compare(g, 2, cv2.CMP_LE),\n",
    "                                               cv2.compare(b, 2, cv2.CMP_LE)))\n",
    "\n",
    "    green_mask = cv2.bitwise_and(cv2.compare(g, 253, cv2.CMP_GE),\n",
    "                                 cv2.bitwise_and(cv2.compare(r, 2, cv2.CMP_LE),\n",
    "                                                 cv2.compare(b, 2, cv2.CMP_LE)))\n",
    "\n",
    "    yellow_mask = cv2.bitwise_and(cv2.compare(r, 253, cv2.CMP_GE),\n",
    "                                  cv2.bitwise_and(cv2.compare(g, 253, cv2.CMP_GE),\n",
    "                                                  cv2.compare(b, 2, cv2.CMP_LE)))\n",
    "\n",
    "    boxes = {'red': [], 'green': [], 'yellow': []}\n",
    "    debug_img = img.copy()\n",
    "\n",
    "    # Process each color mask\n",
    "    for color, mask in [('red', red_mask), ('green', green_mask), ('yellow', yellow_mask)]:\n",
    "        # Find connected components\n",
    "        num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(mask.astype(np.uint8), connectivity=8)\n",
    "\n",
    "        for i in range(1, num_labels):  # Skip background (label 0)\n",
    "            x = stats[i, cv2.CC_STAT_LEFT]\n",
    "            y = stats[i, cv2.CC_STAT_TOP]\n",
    "            w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "            h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "            area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "            # Check if this forms a complete rectangle\n",
    "            # We expect area to be approximately 2*(w+h)-4 for a single-pixel width rectangle\n",
    "            expected_area = 2 * (w + h) - 4\n",
    "            area_ratio = area / expected_area if expected_area > 0 else 0\n",
    "\n",
    "            # Filter valid boxes\n",
    "            if 0.8 < area_ratio < 1.2 and w > 5 and h > 5:\n",
    "                boxes[color].append((x, y, w, h))\n",
    "\n",
    "                # Draw on debug image\n",
    "                color_bgr = (0,0,255) if color == 'red' else (0,255,0) if color == 'green' else (0,255,255)\n",
    "                cv2.rectangle(debug_img, (x,y), (x+w,y+h), color_bgr, 1)\n",
    "\n",
    "    return boxes, debug_img\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tifffile\n",
    "\n",
    "def extract_colored_boxes_hepar(image_path, output_path):\n",
    "    \"\"\"\n",
    "    Extract bounding boxes from Hepar TIFF image with correct colors.\n",
    "    \"\"\"\n",
    "    # Read the TIFF image\n",
    "    img = tifffile.imread(str(image_path))\n",
    "\n",
    "    # Print debug info\n",
    "    print(f\"Image shape: {img.shape}\")\n",
    "    print(f\"Image dtype: {img.dtype}\")\n",
    "\n",
    "    # Convert to uint8 if needed\n",
    "    if img.dtype in [np.float32, np.float64]:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    elif img.dtype != np.uint8:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    height, width = img.shape[:2]\n",
    "\n",
    "    # Color ranges in RGB (matching original image)\n",
    "    color_ranges = {\n",
    "        'red': ([150, 30, 30], [255, 90, 90]),      # class 0\n",
    "        'green': ([30, 150, 30], [90, 255, 90]),    # class 1\n",
    "        'yellow': ([150, 150, 30], [255, 255, 90])  # class 2\n",
    "    }\n",
    "\n",
    "    yolo_annotations = []\n",
    "    debug_img = img.copy()\n",
    "\n",
    "    # Process each color\n",
    "    for class_id, (color_name, (lower, upper)) in enumerate(color_ranges.items()):\n",
    "        # Create mask\n",
    "        try:\n",
    "            mask = cv2.inRange(img, np.array(lower), np.array(upper))\n",
    "        except cv2.error as e:\n",
    "            print(f\"Error creating mask for {color_name}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Filter small boxes\n",
    "            if w < 8 or h < 8:\n",
    "                continue\n",
    "\n",
    "            # Convert to YOLO format\n",
    "            x_center = (x + w/2) / width\n",
    "            y_center = (y + h/2) / height\n",
    "            w = w / width\n",
    "            h = h / height\n",
    "\n",
    "            yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w:.6f} {h:.6f}\")\n",
    "\n",
    "            # Draw on debug image with original colors\n",
    "            color = {\n",
    "                'red': (255, 0, 0),      # Pure red\n",
    "                'green': (0, 255, 0),    # Pure green\n",
    "                'yellow': (255, 255, 0)  # Pure yellow\n",
    "            }[color_name]\n",
    "            cv2.rectangle(debug_img, (x,y), (x+w,y+h), color, 2)\n",
    "\n",
    "    # Save annotations\n",
    "    output_file = Path(output_path) / f\"{Path(image_path).stem}.txt\"\n",
    "    with open(output_file, 'w') as f:\n",
    "        f.write('\\n'.join(yolo_annotations))\n",
    "\n",
    "    # Save debug visualization using RGB color space\n",
    "    debug_path = Path(output_path) / \"debug_visualizations\"\n",
    "    debug_path.mkdir(exist_ok=True)\n",
    "    cv2.imwrite(str(debug_path / f\"{Path(image_path).stem}_debug.png\"), cv2.cvtColor(debug_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    return len(yolo_annotations)\n",
    "\n",
    "# Rest of the code remains the same...\n",
    "def convert_to_yolo_format(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Convert colored box annotations to YOLO format\n",
    "    \"\"\"\n",
    "    os.makedirs(os.path.join(output_dir, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_dir, 'labels'), exist_ok=True)\n",
    "\n",
    "    img = read_tif_image(image_path)\n",
    "    height, width = img.shape[:2]\n",
    "    base_name = os.path.basename(image_path).rsplit('.', 1)[0]\n",
    "\n",
    "    boxes, debug_img = extract_colored_boxes(img)\n",
    "\n",
    "    # Convert to YOLO format\n",
    "    yolo_annotations = []\n",
    "    class_mapping = {'red': 0, 'green': 1, 'yellow': 2}\n",
    "\n",
    "    for color, class_id in class_mapping.items():\n",
    "        for x, y, w, h in boxes[color]:\n",
    "            # Convert to YOLO format (normalized)\n",
    "            x_center = (x + w/2) / width\n",
    "            y_center = (y + h/2) / height\n",
    "            w_normalized = w / width\n",
    "            h_normalized = h / height\n",
    "\n",
    "            yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_normalized:.6f} {h_normalized:.6f}\")\n",
    "\n",
    "    # Save debug image\n",
    "    debug_dir = os.path.join(output_dir, 'debug')\n",
    "    os.makedirs(debug_dir, exist_ok=True)\n",
    "    cv2.imwrite(os.path.join(debug_dir, f\"{base_name}_debug.png\"), debug_img)\n",
    "\n",
    "    # Save original image and annotations\n",
    "    cv2.imwrite(os.path.join(output_dir, 'images', f\"{base_name}.png\"), img)\n",
    "\n",
    "    with open(os.path.join(output_dir, 'labels', f\"{base_name}.txt\"), 'w') as f:\n",
    "        f.write('\\n'.join(yolo_annotations))\n",
    "\n",
    "    print(f\"Processed {base_name}:\")\n",
    "    print(f\"  Red boxes: {len(boxes['red'])}\")\n",
    "    print(f\"  Green boxes: {len(boxes['green'])}\")\n",
    "    print(f\"  Yellow boxes: {len(boxes['yellow'])}\")\n",
    "\n",
    "def process_folder(input_folder, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    tif_files = glob(os.path.join(input_folder, '**/*.tif'), recursive=True)\n",
    "    print(f\"Found {len(tif_files)} TIF files\")\n",
    "\n",
    "    for tif_file in tif_files:\n",
    "        print(f\"\\nProcessing: {tif_file}\")\n",
    "        try:\n",
    "            convert_to_yolo_format(tif_file, output_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {tif_file}: {str(e)}\")\n",
    "\n",
    "    yaml_content = f\"\"\"\n",
    "path: {output_dir}\n",
    "train: images\n",
    "val: images\n",
    "\n",
    "nc: 3\n",
    "names: ['red', 'green', 'yellow']\n",
    "\"\"\"\n",
    "\n",
    "    with open(os.path.join(output_dir, 'data.yaml'), 'w') as f:\n",
    "        f.write(yaml_content.strip())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"HFDA15\"\n",
    "    output_dir = \"yolo_dataset\"\n",
    "    process_folder(input_folder, output_dir)"
   ],
   "id": "f0800fd13cb97d16",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 TIF files\n",
      "\n",
      "Processing: HFDA15/Hepar - HFDA15 3 X40 - 1a.tif\n",
      "Processed Hepar - HFDA15 3 X40 - 1a:\n",
      "  Red boxes: 0\n",
      "  Green boxes: 0\n",
      "  Yellow boxes: 0\n",
      "\n",
      "Processing: HFDA15/Hepar - HFDA15 2 X40 - 1b.tif\n",
      "Processed Hepar - HFDA15 2 X40 - 1b:\n",
      "  Red boxes: 0\n",
      "  Green boxes: 0\n",
      "  Yellow boxes: 0\n",
      "\n",
      "Processing: HFDA15/Hepar - HFDA15 1 X40 - 1.tif\n",
      "Processed Hepar - HFDA15 1 X40 - 1:\n",
      "  Red boxes: 0\n",
      "  Green boxes: 0\n",
      "  Yellow boxes: 0\n",
      "\n",
      "Processing: HFDA15/Hepar - HFDA15 3 X40 - 1b.tif\n",
      "Processed Hepar - HFDA15 3 X40 - 1b:\n",
      "  Red boxes: 0\n",
      "  Green boxes: 0\n",
      "  Yellow boxes: 0\n",
      "\n",
      "Processing: HFDA15/Hepar - HFDA15 1 X40 - 2.tif\n",
      "Processed Hepar - HFDA15 1 X40 - 2:\n",
      "  Red boxes: 0\n",
      "  Green boxes: 0\n",
      "  Yellow boxes: 0\n",
      "\n",
      "Processing: HFDA15/Hepar - HFDA15 2 X40 - 1a.tif\n",
      "Processed Hepar - HFDA15 2 X40 - 1a:\n",
      "  Red boxes: 0\n",
      "  Green boxes: 0\n",
      "  Yellow boxes: 0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:25:02.271263Z",
     "start_time": "2024-11-29T07:25:01.171085Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tifffile\n",
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "\n",
    "def read_tif_image(image_path):\n",
    "    \"\"\"\n",
    "    Read a TIF image and normalize to uint8 if needed.\n",
    "    \"\"\"\n",
    "    img = tifffile.imread(str(image_path))\n",
    "\n",
    "    if img.dtype in [np.float32, np.float64]:\n",
    "        img = (img * 255).astype(np.uint8)\n",
    "    elif img.dtype != np.uint8:\n",
    "        img = img.astype(np.uint8)\n",
    "\n",
    "    if len(img.shape) == 2:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
    "    elif len(img.shape) == 3 and img.shape[2] > 3:\n",
    "        img = img[:, :, :3]\n",
    "\n",
    "    return img\n",
    "\n",
    "def extract_colored_boxes(img, color_ranges):\n",
    "    \"\"\"\n",
    "    Extract bounding boxes for specified color ranges and convert them to YOLO format.\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    yolo_annotations = []\n",
    "    debug_img = img.copy()\n",
    "\n",
    "    for class_id, (color_name, (lower, upper)) in enumerate(color_ranges.items()):\n",
    "        # Create a binary mask for the color range\n",
    "        mask = cv2.inRange(img, np.array(lower), np.array(upper))\n",
    "\n",
    "        # Find contours\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        for contour in contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "\n",
    "            # Filter out small boxes\n",
    "            if w < 8 or h < 8:\n",
    "                continue\n",
    "\n",
    "            # Convert to YOLO format (normalized)\n",
    "            x_center = (x + w / 2) / width\n",
    "            y_center = (y + h / 2) / height\n",
    "            w_normalized = w / width\n",
    "            h_normalized = h / height\n",
    "\n",
    "            yolo_annotations.append(f\"{class_id} {x_center:.6f} {y_center:.6f} {w_normalized:.6f} {h_normalized:.6f}\")\n",
    "\n",
    "            # Draw on debug image\n",
    "            color = {\n",
    "                'red': (255, 0, 0),\n",
    "                'green': (0, 255, 0),\n",
    "                'yellow': (255, 255, 0)\n",
    "            }[color_name]\n",
    "            cv2.rectangle(debug_img, (x, y), (x + w, y + h), color, 2)\n",
    "\n",
    "    return yolo_annotations, debug_img\n",
    "\n",
    "def convert_to_yolo_format(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Convert bounding boxes for a single image to YOLO format.\n",
    "    \"\"\"\n",
    "    img = read_tif_image(image_path)\n",
    "    base_name = Path(image_path).stem\n",
    "    output_image_dir = Path(output_dir) / \"images\"\n",
    "    output_label_dir = Path(output_dir) / \"labels\"\n",
    "    output_debug_dir = Path(output_dir) / \"debug\"\n",
    "\n",
    "    output_image_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_label_dir.mkdir(parents=True, exist_ok=True)\n",
    "    output_debug_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Define color ranges\n",
    "    color_ranges = {\n",
    "        'red': ([150, 30, 30], [255, 90, 90]),      # class 0\n",
    "        'green': ([30, 150, 30], [90, 255, 90]),    # class 1\n",
    "        'yellow': ([150, 150, 30], [255, 255, 90])  # class 2\n",
    "    }\n",
    "\n",
    "    # Extract YOLO annotations and debug image\n",
    "    yolo_annotations, debug_img = extract_colored_boxes(img, color_ranges)\n",
    "\n",
    "    # Save YOLO annotations\n",
    "    with open(output_label_dir / f\"{base_name}.txt\", 'w') as f:\n",
    "        f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "    # Save the image and debug visualization\n",
    "    cv2.imwrite(str(output_image_dir / f\"{base_name}.png\"), img)\n",
    "    cv2.imwrite(str(output_debug_dir / f\"{base_name}_debug.png\"), cv2.cvtColor(debug_img, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "    return len(yolo_annotations)\n",
    "\n",
    "def process_folder(input_folder, output_dir):\n",
    "    \"\"\"\n",
    "    Process all TIF images in a folder and convert them to YOLO format.\n",
    "    \"\"\"\n",
    "    tif_files = glob(os.path.join(input_folder, '**/*.tif'), recursive=True)\n",
    "    print(f\"Found {len(tif_files)} TIF files\")\n",
    "\n",
    "    for tif_file in tif_files:\n",
    "        print(f\"Processing: {tif_file}\")\n",
    "        try:\n",
    "            annotations_count = convert_to_yolo_format(tif_file, output_dir)\n",
    "            print(f\"Generated {annotations_count} annotations for {tif_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {tif_file}: {e}\")\n",
    "\n",
    "    # Create a YAML file for YOLO training\n",
    "    yaml_content = f\"\"\"\n",
    "path: {output_dir}\n",
    "train: images\n",
    "val: images\n",
    "\n",
    "nc: 3\n",
    "names: ['red', 'green', 'yellow']\n",
    "\"\"\"\n",
    "    with open(os.path.join(output_dir, 'data.yaml'), 'w') as f:\n",
    "        f.write(yaml_content.strip())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"HFDA15\"\n",
    "    output_dir = \"yolo_dataset\"\n",
    "    process_folder(input_folder, output_dir)\n"
   ],
   "id": "71ba7ac43bd5d0b2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 TIF files\n",
      "Processing: HFDA15/Hepar - HFDA15 1 X40 - 1.tif\n",
      "Generated 81 annotations for HFDA15/Hepar - HFDA15 1 X40 - 1.tif\n",
      "Processing: HFDA15/Hepar - HFDA15 1 X40 - 2.tif\n",
      "Generated 103 annotations for HFDA15/Hepar - HFDA15 1 X40 - 2.tif\n",
      "Processing: HFDA15/Hepar - HFDA15 2 X40 - 1a.tif\n",
      "Generated 63 annotations for HFDA15/Hepar - HFDA15 2 X40 - 1a.tif\n",
      "Processing: HFDA15/Hepar - HFDA15 2 X40 - 1b.tif\n",
      "Error processing HFDA15/Hepar - HFDA15 2 X40 - 1b.tif: not a TIFF file b''\n",
      "Processing: HFDA15/Hepar - HFDA15 3 X40 - 1a.tif\n",
      "Error processing HFDA15/Hepar - HFDA15 3 X40 - 1a.tif: not a TIFF file b''\n",
      "Processing: HFDA15/Hepar - HFDA15 3 X40 - 1b.tif\n",
      "Error processing HFDA15/Hepar - HFDA15 3 X40 - 1b.tif: not a TIFF file b''\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:27:53.160326Z",
     "start_time": "2024-11-29T07:27:52.639381Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "\n",
    "def process_image(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single image to extract bounding boxes for red, green, and yellow,\n",
    "    generate YOLO labels, and save debug images.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image_cv = cv2.imread(image_path)\n",
    "\n",
    "    # Convert to RGB (OpenCV loads images in BGR by default)\n",
    "    image_rgb = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Define the color ranges for red, green, and yellow\n",
    "    color_ranges = {\n",
    "        \"red\": ([200, 0, 0], [255, 50, 50]),       # Lower and upper bounds for red\n",
    "        \"green\": ([0, 200, 0], [50, 255, 50]),     # Lower and upper bounds for green\n",
    "        \"yellow\": ([200, 200, 0], [255, 255, 50])  # Lower and upper bounds for yellow\n",
    "    }\n",
    "\n",
    "    # Convert the bounds to numpy arrays\n",
    "    color_masks = {}\n",
    "    for color, (lower, upper) in color_ranges.items():\n",
    "        lower_bound = np.array(lower, dtype=\"uint8\")\n",
    "        upper_bound = np.array(upper, dtype=\"uint8\")\n",
    "        # Create masks for each color\n",
    "        mask = cv2.inRange(image_rgb, lower_bound, upper_bound)\n",
    "        color_masks[color] = mask\n",
    "\n",
    "    # Count and extract the coordinates of bounding boxes for each color\n",
    "    color_bounding_boxes = {}\n",
    "    yolo_annotations = []\n",
    "    debug_img = image_cv.copy()\n",
    "\n",
    "    class_mapping = {\"red\": 0, \"green\": 1, \"yellow\": 2}\n",
    "    height, width = image_rgb.shape[:2]\n",
    "\n",
    "    for color, mask in color_masks.items():\n",
    "        # Find contours for each color\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "        color_bounding_boxes[color] = bounding_boxes\n",
    "\n",
    "        # Convert bounding boxes to YOLO format and annotate the debug image\n",
    "        for bbox in bounding_boxes:\n",
    "            x, y, w, h = bbox\n",
    "            # YOLO format (normalized)\n",
    "            x_center = (x + w / 2) / width\n",
    "            y_center = (y + h / 2) / height\n",
    "            w_norm = w / width\n",
    "            h_norm = h / height\n",
    "            yolo_annotations.append(f\"{class_mapping[color]} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "\n",
    "            # Draw rectangle on debug image\n",
    "            color_bgr = (0, 0, 255) if color == \"red\" else (0, 255, 0) if color == \"green\" else (0, 255, 255)\n",
    "            cv2.rectangle(debug_img, (x, y), (x + w, y + h), color_bgr, 2)\n",
    "\n",
    "    # Save YOLO labels\n",
    "    base_name = Path(image_path).stem\n",
    "    labels_dir = Path(output_dir) / \"labels\"\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(labels_dir / f\"{base_name}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "    # Save debug image\n",
    "    debug_dir = Path(output_dir) / \"debug\"\n",
    "    debug_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(debug_dir / f\"{base_name}_debug.png\"), debug_img)\n",
    "\n",
    "    print(f\"Processed {image_path}: {len(yolo_annotations)} annotations\")\n",
    "\n",
    "def process_images(input_folder, output_dir):\n",
    "    \"\"\"\n",
    "    Process all images in the input folder and generate YOLO labels and debug images.\n",
    "    \"\"\"\n",
    "    image_paths = glob(os.path.join(input_folder, \"*.*\"))\n",
    "    print(f\"Found {len(image_paths)} images\")\n",
    "\n",
    "    for image_path in image_paths:\n",
    "        try:\n",
    "            process_image(image_path, output_dir)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_folder = \"HFDA15\"  # Replace with the folder containing your images\n",
    "    output_dir = \"output_annotations\"      # Replace with your desired output directory\n",
    "    process_images(input_folder, output_dir)\n"
   ],
   "id": "6ba97818f233799",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images\n",
      "Processed HFDA15/Hepar - HFDA15 1 X40 - 1.tif: 83 annotations\n",
      "Processed HFDA15/Hepar - HFDA15 1 X40 - 2.tif: 56 annotations\n",
      "Processed HFDA15/Hepar - HFDA15 2 X40 - 1a.tif: 94 annotations\n",
      "Error processing HFDA15/Hepar - HFDA15 2 X40 - 1b.tif: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Error processing HFDA15/Hepar - HFDA15 3 X40 - 1a.tif: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n",
      "Error processing HFDA15/Hepar - HFDA15 3 X40 - 1b.tif: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T07:33:27.554816Z",
     "start_time": "2024-11-29T07:33:27.376091Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def refined_process_image(image_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a single image with improved bounding box detection to generate YOLO labels\n",
    "    and save debug images.\n",
    "    \"\"\"\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: File not found - {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Load the image\n",
    "    image_cv = cv2.imread(image_path)\n",
    "\n",
    "    # Check if the image was loaded successfully\n",
    "    if image_cv is None:\n",
    "        print(f\"Error: Failed to load image - {image_path}\")\n",
    "        return\n",
    "\n",
    "    # Convert to RGB (OpenCV loads images in BGR by default)\n",
    "    image_rgb = cv2.cvtColor(image_cv, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Define the color ranges for red, green, and yellow with refined thresholds\n",
    "    color_ranges = {\n",
    "        \"red\": ([180, 0, 0], [255, 80, 80]),       # Adjusted lower and upper bounds for red\n",
    "        \"green\": ([0, 180, 0], [80, 255, 80]),     # Adjusted lower and upper bounds for green\n",
    "        \"yellow\": ([180, 180, 0], [255, 255, 80])  # Adjusted lower and upper bounds for yellow\n",
    "    }\n",
    "\n",
    "    # Convert the bounds to numpy arrays\n",
    "    color_masks = {}\n",
    "    for color, (lower, upper) in color_ranges.items():\n",
    "        lower_bound = np.array(lower, dtype=\"uint8\")\n",
    "        upper_bound = np.array(upper, dtype=\"uint8\")\n",
    "        # Create masks for each color\n",
    "        mask = cv2.inRange(image_rgb, lower_bound, upper_bound)\n",
    "        color_masks[color] = mask\n",
    "\n",
    "    # Extract the bounding boxes and generate YOLO labels\n",
    "    color_bounding_boxes = {}\n",
    "    yolo_annotations = []\n",
    "    debug_img = image_cv.copy()\n",
    "\n",
    "    class_mapping = {\"red\": 0, \"green\": 1, \"yellow\": 2}\n",
    "    height, width = image_rgb.shape[:2]\n",
    "\n",
    "    for color, mask in color_masks.items():\n",
    "        # Find contours for each color\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        bounding_boxes = [cv2.boundingRect(contour) for contour in contours]\n",
    "        color_bounding_boxes[color] = bounding_boxes\n",
    "\n",
    "        # Convert bounding boxes to YOLO format and annotate the debug image\n",
    "        for bbox in bounding_boxes:\n",
    "            x, y, w, h = bbox\n",
    "            # Filter out noise and very small boxes\n",
    "            if w < 5 or h < 5:\n",
    "                continue\n",
    "\n",
    "            # YOLO format (normalized)\n",
    "            x_center = (x + w / 2) / width\n",
    "            y_center = (y + h / 2) / height\n",
    "            w_norm = w / width\n",
    "            h_norm = h / height\n",
    "            yolo_annotations.append(f\"{class_mapping[color]} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\")\n",
    "\n",
    "            # Draw rectangle on debug image\n",
    "            color_bgr = (0, 0, 255) if color == \"red\" else (0, 255, 0) if color == \"green\" else (0, 255, 255)\n",
    "            cv2.rectangle(debug_img, (x, y), (x + w, y + h), color_bgr, 2)\n",
    "\n",
    "    # Save YOLO labels\n",
    "    base_name = Path(image_path).stem\n",
    "    labels_dir = Path(output_dir) / \"labels\"\n",
    "    labels_dir.mkdir(parents=True, exist_ok=True)\n",
    "    with open(labels_dir / f\"{base_name}.txt\", \"w\") as f:\n",
    "        f.write(\"\\n\".join(yolo_annotations))\n",
    "\n",
    "    # Save debug image\n",
    "    debug_dir = Path(output_dir) / \"debug\"\n",
    "    debug_dir.mkdir(parents=True, exist_ok=True)\n",
    "    cv2.imwrite(str(debug_dir / f\"{base_name}_debug.png\"), debug_img)\n",
    "\n",
    "    print(f\"Processed {image_path}: {len(yolo_annotations)} annotations\")\n",
    "\n",
    "# Rerun the function with error handling\n",
    "refined_process_image(\"./HFDA15/Hepar - HFDA15 1 X40 - 1.tif\", \"output_dir\")\n"
   ],
   "id": "1f97858e95d6c32f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed ./HFDA15/Hepar - HFDA15 1 X40 - 1.tif: 81 annotations\n"
     ]
    }
   ],
   "execution_count": 18
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
