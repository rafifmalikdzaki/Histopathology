{"format": "torch", "nodes": [{"name": "model", "id": 139736531548816, "class_name": "DAE_KAN_Attention(\n  (ae_encoder): Autoencoder_Encoder(\n    (kan): KAN_Convolutional_Layer(\n      (convs): ModuleList(\n        (0): KAN_Convolution(\n          (conv): KANLinear(\n            (base_activation): SiLU()\n          )\n        )\n      )\n    )\n    (encoder1): Sequential(\n      (0): Conv2d(3, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (encoder2): Sequential(\n      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (encoder3): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (ECA_Net): ECALayer(\n      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n      (sigmoid): Sigmoid()\n    )\n    (decoder1): Sequential(\n      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): ConvTranspose2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ELU(alpha=1.0, inplace=True)\n    )\n    (decoder2): Sequential(\n      (0): ConvTranspose2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n  )\n  (bottleneck): Autoencoder_BottleNeck(\n    (encoder1): Sequential(\n      (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (attn1): BAM(\n      (channel_attn): ChannelGate(\n        (avgpool): AdaptiveAvgPool2d(output_size=1)\n        (mlp): Sequential(\n          (0): Linear(in_features=384, out_features=24, bias=True)\n          (1): ReLU(inplace=True)\n          (2): Linear(in_features=24, out_features=384, bias=True)\n        )\n        (bn): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (spatial_attn): SpatialGate(\n        (conv1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n        (conv2): Sequential(\n          (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n          (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n          (4): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n        (conv3): Conv2d(24, 1, kernel_size=(1, 1), stride=(1, 1))\n        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (encoder2): Sequential(\n      (0): Conv2d(384, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (attn2): BAM(\n      (channel_attn): ChannelGate(\n        (avgpool): AdaptiveAvgPool2d(output_size=1)\n        (mlp): Sequential(\n          (0): Linear(in_features=16, out_features=1, bias=True)\n          (1): ReLU(inplace=True)\n          (2): Linear(in_features=1, out_features=16, bias=True)\n        )\n        (bn): BatchNorm1d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (spatial_attn): SpatialGate(\n        (conv1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n        (conv2): Sequential(\n          (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n          (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n          (3): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n          (4): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (5): ReLU(inplace=True)\n        )\n        (conv3): Conv2d(1, 1, kernel_size=(1, 1), stride=(1, 1))\n        (bn): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (decoder): Sequential(\n      (0): ConvTranspose2d(16, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n  )\n  (ae_decoder): Autoencoder_Decoder(\n    (kan): KAN_Convolutional_Layer(\n      (convs): ModuleList(\n        (0): KAN_Convolution(\n          (conv): KANLinear(\n            (base_activation): SiLU()\n          )\n        )\n      )\n    )\n    (encoder1): Sequential(\n      (0): ConvTranspose2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (encoder2): Sequential(\n      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (encoder3): Sequential(\n      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (ECA_Net): ECALayer(\n      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n      (sigmoid): Sigmoid()\n    )\n    (decoder1): Sequential(\n      (0): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (1): ConvTranspose2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (3): ELU(alpha=1.0, inplace=True)\n    )\n    (decoder2): Sequential(\n      (0): ConvTranspose2d(128, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (Output_Layer): Sequential(\n      (0): ConvTranspose2d(384, 3, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n      (1): BatchNorm2d(3, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): ELU(alpha=1.0, inplace=True)\n    )\n    (reconstructtion): KAN_Convolutional_Layer(\n      (convs): ModuleList(\n        (0): KAN_Convolution(\n          (conv): KANLinear(\n            (base_activation): SiLU()\n          )\n        )\n      )\n    )\n  )\n)", "parameters": [["ae_encoder.kan.convs.0.conv.base_weight", [1, 25]], ["ae_encoder.kan.convs.0.conv.spline_weight", [1, 25, 8]], ["ae_encoder.kan.convs.0.conv.spline_scaler", [1, 25]], ["ae_encoder.encoder1.0.weight", [384, 3, 3, 3]], ["ae_encoder.encoder1.0.bias", [384]], ["ae_encoder.encoder1.1.weight", [384]], ["ae_encoder.encoder1.1.bias", [384]], ["ae_encoder.encoder2.0.weight", [128, 384, 3, 3]], ["ae_encoder.encoder2.0.bias", [128]], ["ae_encoder.encoder2.1.weight", [128]], ["ae_encoder.encoder2.1.bias", [128]], ["ae_encoder.encoder3.0.weight", [64, 128, 3, 3]], ["ae_encoder.encoder3.0.bias", [64]], ["ae_encoder.encoder3.1.weight", [64]], ["ae_encoder.encoder3.1.bias", [64]], ["ae_encoder.ECA_Net.conv.weight", [1, 1, 3]], ["ae_encoder.decoder1.0.weight", [64]], ["ae_encoder.decoder1.0.bias", [64]], ["ae_encoder.decoder1.1.weight", [64, 128, 3, 3]], ["ae_encoder.decoder1.1.bias", [128]], ["ae_encoder.decoder1.2.weight", [128]], ["ae_encoder.decoder1.2.bias", [128]], ["ae_encoder.decoder2.0.weight", [128, 384, 3, 3]], ["ae_encoder.decoder2.0.bias", [384]], ["ae_encoder.decoder2.1.weight", [384]], ["ae_encoder.decoder2.1.bias", [384]], ["bottleneck.encoder1.0.weight", [384, 384, 3, 3]], ["bottleneck.encoder1.0.bias", [384]], ["bottleneck.encoder1.1.weight", [384]], ["bottleneck.encoder1.1.bias", [384]], ["bottleneck.attn1.channel_attn.mlp.0.weight", [24, 384]], ["bottleneck.attn1.channel_attn.mlp.0.bias", [24]], ["bottleneck.attn1.channel_attn.mlp.2.weight", [384, 24]], ["bottleneck.attn1.channel_attn.mlp.2.bias", [384]], ["bottleneck.attn1.channel_attn.bn.weight", [384]], ["bottleneck.attn1.channel_attn.bn.bias", [384]], ["bottleneck.attn1.spatial_attn.conv1.weight", [24, 384, 1, 1]], ["bottleneck.attn1.spatial_attn.conv1.bias", [24]], ["bottleneck.attn1.spatial_attn.conv2.0.weight", [24, 24, 3, 3]], ["bottleneck.attn1.spatial_attn.conv2.0.bias", [24]], ["bottleneck.attn1.spatial_attn.conv2.1.weight", [24]], ["bottleneck.attn1.spatial_attn.conv2.1.bias", [24]], ["bottleneck.attn1.spatial_attn.conv2.3.weight", [24, 24, 3, 3]], ["bottleneck.attn1.spatial_attn.conv2.3.bias", [24]], ["bottleneck.attn1.spatial_attn.conv2.4.weight", [24]], ["bottleneck.attn1.spatial_attn.conv2.4.bias", [24]], ["bottleneck.attn1.spatial_attn.conv3.weight", [1, 24, 1, 1]], ["bottleneck.attn1.spatial_attn.conv3.bias", [1]], ["bottleneck.attn1.spatial_attn.bn.weight", [1]], ["bottleneck.attn1.spatial_attn.bn.bias", [1]], ["bottleneck.encoder2.0.weight", [16, 384, 3, 3]], ["bottleneck.encoder2.0.bias", [16]], ["bottleneck.encoder2.1.weight", [16]], ["bottleneck.encoder2.1.bias", [16]], ["bottleneck.attn2.channel_attn.mlp.0.weight", [1, 16]], ["bottleneck.attn2.channel_attn.mlp.0.bias", [1]], ["bottleneck.attn2.channel_attn.mlp.2.weight", [16, 1]], ["bottleneck.attn2.channel_attn.mlp.2.bias", [16]], ["bottleneck.attn2.channel_attn.bn.weight", [16]], ["bottleneck.attn2.channel_attn.bn.bias", [16]], ["bottleneck.attn2.spatial_attn.conv1.weight", [1, 16, 1, 1]], ["bottleneck.attn2.spatial_attn.conv1.bias", [1]], ["bottleneck.attn2.spatial_attn.conv2.0.weight", [1, 1, 3, 3]], ["bottleneck.attn2.spatial_attn.conv2.0.bias", [1]], ["bottleneck.attn2.spatial_attn.conv2.1.weight", [1]], ["bottleneck.attn2.spatial_attn.conv2.1.bias", [1]], ["bottleneck.attn2.spatial_attn.conv2.3.weight", [1, 1, 3, 3]], ["bottleneck.attn2.spatial_attn.conv2.3.bias", [1]], ["bottleneck.attn2.spatial_attn.conv2.4.weight", [1]], ["bottleneck.attn2.spatial_attn.conv2.4.bias", [1]], ["bottleneck.attn2.spatial_attn.conv3.weight", [1, 1, 1, 1]], ["bottleneck.attn2.spatial_attn.conv3.bias", [1]], ["bottleneck.attn2.spatial_attn.bn.weight", [1]], ["bottleneck.attn2.spatial_attn.bn.bias", [1]], ["bottleneck.decoder.0.weight", [16, 128, 3, 3]], ["bottleneck.decoder.0.bias", [128]], ["bottleneck.decoder.1.weight", [128]], ["bottleneck.decoder.1.bias", [128]], ["ae_decoder.kan.convs.0.conv.base_weight", [1, 25]], ["ae_decoder.kan.convs.0.conv.spline_weight", [1, 25, 8]], ["ae_decoder.kan.convs.0.conv.spline_scaler", [1, 25]], ["ae_decoder.encoder1.0.weight", [128, 384, 3, 3]], ["ae_decoder.encoder1.0.bias", [384]], ["ae_decoder.encoder1.1.weight", [384]], ["ae_decoder.encoder1.1.bias", [384]], ["ae_decoder.encoder2.0.weight", [128, 384, 3, 3]], ["ae_decoder.encoder2.0.bias", [128]], ["ae_decoder.encoder2.1.weight", [128]], ["ae_decoder.encoder2.1.bias", [128]], ["ae_decoder.encoder3.0.weight", [64, 128, 3, 3]], ["ae_decoder.encoder3.0.bias", [64]], ["ae_decoder.encoder3.1.weight", [64]], ["ae_decoder.encoder3.1.bias", [64]], ["ae_decoder.ECA_Net.conv.weight", [1, 1, 3]], ["ae_decoder.decoder1.0.weight", [64]], ["ae_decoder.decoder1.0.bias", [64]], ["ae_decoder.decoder1.1.weight", [64, 128, 3, 3]], ["ae_decoder.decoder1.1.bias", [128]], ["ae_decoder.decoder1.2.weight", [128]], ["ae_decoder.decoder1.2.bias", [128]], ["ae_decoder.decoder2.0.weight", [128, 384, 3, 3]], ["ae_decoder.decoder2.0.bias", [384]], ["ae_decoder.decoder2.1.weight", [384]], ["ae_decoder.decoder2.1.bias", [384]], ["ae_decoder.Output_Layer.0.weight", [384, 3, 3, 3]], ["ae_decoder.Output_Layer.0.bias", [3]], ["ae_decoder.Output_Layer.1.weight", [3]], ["ae_decoder.Output_Layer.1.bias", [3]], ["ae_decoder.reconstructtion.convs.0.conv.base_weight", [1, 9]], ["ae_decoder.reconstructtion.convs.0.conv.spline_weight", [1, 9, 8]], ["ae_decoder.reconstructtion.convs.0.conv.spline_scaler", [1, 9]]], "output_shape": [[12, 384, 64, 64], [12, 3, 128, 128], [12, 16, 16, 16]], "num_parameters": [25, 200, 25, 10368, 384, 384, 384, 442368, 128, 128, 128, 73728, 64, 64, 64, 3, 64, 64, 73728, 128, 128, 128, 442368, 384, 384, 384, 1327104, 384, 384, 384, 9216, 24, 9216, 384, 384, 384, 9216, 24, 5184, 24, 24, 24, 5184, 24, 24, 24, 24, 1, 1, 1, 55296, 16, 16, 16, 16, 1, 16, 16, 16, 16, 16, 1, 9, 1, 1, 1, 9, 1, 1, 1, 1, 1, 1, 1, 18432, 128, 128, 128, 25, 200, 25, 442368, 384, 384, 384, 442368, 128, 128, 128, 73728, 64, 64, 64, 3, 64, 64, 73728, 128, 128, 128, 442368, 384, 384, 384, 10368, 3, 3, 3, 9, 72, 9]}], "edges": []}